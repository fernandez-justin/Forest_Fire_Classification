{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
    "\n",
    "from sklearn.feature_selection import RFECV\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.utils import resample\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, f_regression,mutual_info_regression\n",
    "# for feature selection\n",
    "from sklearn.feature_selection import RFECV\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.feature_selection import chi2, f_classif, mutual_info_classif\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/cleaned_fire_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = [\n",
    "    'Unnamed: 0'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=cols_to_drop,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stat_cause_descr</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>Temp_pre_30</th>\n",
       "      <th>Temp_pre_15</th>\n",
       "      <th>Temp_pre_7</th>\n",
       "      <th>Wind_pre_30</th>\n",
       "      <th>Wind_pre_15</th>\n",
       "      <th>Wind_pre_7</th>\n",
       "      <th>Hum_pre_30</th>\n",
       "      <th>Hum_pre_15</th>\n",
       "      <th>Hum_pre_7</th>\n",
       "      <th>Prec_pre_30</th>\n",
       "      <th>Prec_pre_15</th>\n",
       "      <th>Prec_pre_7</th>\n",
       "      <th>remoteness</th>\n",
       "      <th>target</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>temp_avg</th>\n",
       "      <th>is_remote</th>\n",
       "      <th>did_rain</th>\n",
       "      <th>Temp_pre_30_bin</th>\n",
       "      <th>Temp_pre_15_bin</th>\n",
       "      <th>Temp_pre_7_bin</th>\n",
       "      <th>discovery_month_Aug</th>\n",
       "      <th>discovery_month_Dec</th>\n",
       "      <th>discovery_month_Feb</th>\n",
       "      <th>discovery_month_Jan</th>\n",
       "      <th>discovery_month_Jul</th>\n",
       "      <th>discovery_month_Jun</th>\n",
       "      <th>discovery_month_Mar</th>\n",
       "      <th>discovery_month_May</th>\n",
       "      <th>discovery_month_Nov</th>\n",
       "      <th>discovery_month_Oct</th>\n",
       "      <th>discovery_month_Sep</th>\n",
       "      <th>state_AL</th>\n",
       "      <th>state_AR</th>\n",
       "      <th>state_AZ</th>\n",
       "      <th>state_CA</th>\n",
       "      <th>state_CO</th>\n",
       "      <th>state_CT</th>\n",
       "      <th>state_DE</th>\n",
       "      <th>state_FL</th>\n",
       "      <th>state_GA</th>\n",
       "      <th>state_HI</th>\n",
       "      <th>state_IA</th>\n",
       "      <th>state_ID</th>\n",
       "      <th>state_IL</th>\n",
       "      <th>state_IN</th>\n",
       "      <th>state_KS</th>\n",
       "      <th>state_KY</th>\n",
       "      <th>state_LA</th>\n",
       "      <th>state_MA</th>\n",
       "      <th>state_MD</th>\n",
       "      <th>state_ME</th>\n",
       "      <th>state_MI</th>\n",
       "      <th>state_MN</th>\n",
       "      <th>state_MO</th>\n",
       "      <th>state_MS</th>\n",
       "      <th>state_MT</th>\n",
       "      <th>state_NC</th>\n",
       "      <th>state_ND</th>\n",
       "      <th>state_NE</th>\n",
       "      <th>state_NH</th>\n",
       "      <th>state_NJ</th>\n",
       "      <th>state_NM</th>\n",
       "      <th>state_NV</th>\n",
       "      <th>state_NY</th>\n",
       "      <th>state_OH</th>\n",
       "      <th>state_OK</th>\n",
       "      <th>state_OR</th>\n",
       "      <th>state_PA</th>\n",
       "      <th>state_PR</th>\n",
       "      <th>state_RI</th>\n",
       "      <th>state_SC</th>\n",
       "      <th>state_SD</th>\n",
       "      <th>state_TN</th>\n",
       "      <th>state_TX</th>\n",
       "      <th>state_UT</th>\n",
       "      <th>state_VA</th>\n",
       "      <th>state_VT</th>\n",
       "      <th>state_WA</th>\n",
       "      <th>state_WI</th>\n",
       "      <th>state_WV</th>\n",
       "      <th>state_WY</th>\n",
       "      <th>Vegetation_4</th>\n",
       "      <th>Vegetation_9</th>\n",
       "      <th>Vegetation_12</th>\n",
       "      <th>Vegetation_14</th>\n",
       "      <th>Vegetation_15</th>\n",
       "      <th>Vegetation_16</th>\n",
       "      <th>longitude_bin</th>\n",
       "      <th>west_coast</th>\n",
       "      <th>very_windy_30</th>\n",
       "      <th>very_windy_15</th>\n",
       "      <th>very_windy_7</th>\n",
       "      <th>low_humid_30</th>\n",
       "      <th>low_humid_15</th>\n",
       "      <th>low_humid_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>18.105072</td>\n",
       "      <td>-66.753044</td>\n",
       "      <td>76.065753</td>\n",
       "      <td>76.490462</td>\n",
       "      <td>76.824675</td>\n",
       "      <td>4.341807</td>\n",
       "      <td>3.492857</td>\n",
       "      <td>3.262092</td>\n",
       "      <td>78.216590</td>\n",
       "      <td>76.793750</td>\n",
       "      <td>76.381579</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017923</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2007</td>\n",
       "      <td>76.460297</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>35.038330</td>\n",
       "      <td>-87.610000</td>\n",
       "      <td>45.596180</td>\n",
       "      <td>44.618000</td>\n",
       "      <td>32.618353</td>\n",
       "      <td>2.709764</td>\n",
       "      <td>2.881707</td>\n",
       "      <td>1.976471</td>\n",
       "      <td>70.840000</td>\n",
       "      <td>65.858911</td>\n",
       "      <td>55.505882</td>\n",
       "      <td>59.8</td>\n",
       "      <td>8.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.184355</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2006</td>\n",
       "      <td>40.944178</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>34.947800</td>\n",
       "      <td>-88.722500</td>\n",
       "      <td>40.949474</td>\n",
       "      <td>42.408979</td>\n",
       "      <td>42.005750</td>\n",
       "      <td>3.364499</td>\n",
       "      <td>2.923830</td>\n",
       "      <td>2.695833</td>\n",
       "      <td>75.531629</td>\n",
       "      <td>75.868613</td>\n",
       "      <td>76.812834</td>\n",
       "      <td>168.8</td>\n",
       "      <td>42.2</td>\n",
       "      <td>18.1</td>\n",
       "      <td>0.194544</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2004</td>\n",
       "      <td>41.788067</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>39.641400</td>\n",
       "      <td>-119.308300</td>\n",
       "      <td>61.296741</td>\n",
       "      <td>66.193126</td>\n",
       "      <td>64.656615</td>\n",
       "      <td>4.054982</td>\n",
       "      <td>3.398329</td>\n",
       "      <td>3.671282</td>\n",
       "      <td>44.778429</td>\n",
       "      <td>37.140811</td>\n",
       "      <td>35.353846</td>\n",
       "      <td>10.4</td>\n",
       "      <td>7.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.487447</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2005</td>\n",
       "      <td>64.048828</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>30.904720</td>\n",
       "      <td>-93.557500</td>\n",
       "      <td>62.333490</td>\n",
       "      <td>62.596009</td>\n",
       "      <td>68.782609</td>\n",
       "      <td>1.331257</td>\n",
       "      <td>1.472949</td>\n",
       "      <td>1.424783</td>\n",
       "      <td>72.899478</td>\n",
       "      <td>75.061381</td>\n",
       "      <td>77.924623</td>\n",
       "      <td>28.4</td>\n",
       "      <td>27.5</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.241894</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>2005</td>\n",
       "      <td>64.570703</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36530</th>\n",
       "      <td>0</td>\n",
       "      <td>37.606667</td>\n",
       "      <td>-96.422500</td>\n",
       "      <td>38.635038</td>\n",
       "      <td>37.471742</td>\n",
       "      <td>39.987614</td>\n",
       "      <td>5.100510</td>\n",
       "      <td>5.694737</td>\n",
       "      <td>4.975000</td>\n",
       "      <td>62.971774</td>\n",
       "      <td>69.376658</td>\n",
       "      <td>68.118919</td>\n",
       "      <td>20.1</td>\n",
       "      <td>18.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.365622</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2015</td>\n",
       "      <td>38.698132</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36531</th>\n",
       "      <td>0</td>\n",
       "      <td>40.394700</td>\n",
       "      <td>-104.564600</td>\n",
       "      <td>67.722291</td>\n",
       "      <td>66.728555</td>\n",
       "      <td>65.620761</td>\n",
       "      <td>2.507911</td>\n",
       "      <td>2.553364</td>\n",
       "      <td>2.638542</td>\n",
       "      <td>51.010341</td>\n",
       "      <td>50.264501</td>\n",
       "      <td>48.204861</td>\n",
       "      <td>4.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.199532</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2015</td>\n",
       "      <td>66.690536</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36532</th>\n",
       "      <td>0</td>\n",
       "      <td>39.180000</td>\n",
       "      <td>-96.784167</td>\n",
       "      <td>67.497438</td>\n",
       "      <td>62.404308</td>\n",
       "      <td>66.054190</td>\n",
       "      <td>3.259176</td>\n",
       "      <td>2.705398</td>\n",
       "      <td>3.196648</td>\n",
       "      <td>65.671410</td>\n",
       "      <td>61.839572</td>\n",
       "      <td>54.625698</td>\n",
       "      <td>35.4</td>\n",
       "      <td>8.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.331501</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2015</td>\n",
       "      <td>65.318645</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36533</th>\n",
       "      <td>0</td>\n",
       "      <td>37.262607</td>\n",
       "      <td>-119.511139</td>\n",
       "      <td>83.165726</td>\n",
       "      <td>83.165726</td>\n",
       "      <td>82.700000</td>\n",
       "      <td>2.649395</td>\n",
       "      <td>2.649395</td>\n",
       "      <td>2.667722</td>\n",
       "      <td>43.755556</td>\n",
       "      <td>43.755556</td>\n",
       "      <td>44.443975</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.097682</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2015</td>\n",
       "      <td>83.010484</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36534</th>\n",
       "      <td>0</td>\n",
       "      <td>38.843988</td>\n",
       "      <td>-122.759707</td>\n",
       "      <td>70.862404</td>\n",
       "      <td>70.362500</td>\n",
       "      <td>71.533571</td>\n",
       "      <td>1.795485</td>\n",
       "      <td>1.628065</td>\n",
       "      <td>1.036905</td>\n",
       "      <td>50.521912</td>\n",
       "      <td>46.310627</td>\n",
       "      <td>37.178571</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.167305</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2015</td>\n",
       "      <td>70.919492</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36535 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       stat_cause_descr   latitude   longitude  Temp_pre_30  Temp_pre_15  \\\n",
       "0                     0  18.105072  -66.753044    76.065753    76.490462   \n",
       "1                     0  35.038330  -87.610000    45.596180    44.618000   \n",
       "2                     0  34.947800  -88.722500    40.949474    42.408979   \n",
       "3                     0  39.641400 -119.308300    61.296741    66.193126   \n",
       "4                     0  30.904720  -93.557500    62.333490    62.596009   \n",
       "...                 ...        ...         ...          ...          ...   \n",
       "36530                 0  37.606667  -96.422500    38.635038    37.471742   \n",
       "36531                 0  40.394700 -104.564600    67.722291    66.728555   \n",
       "36532                 0  39.180000  -96.784167    67.497438    62.404308   \n",
       "36533                 0  37.262607 -119.511139    83.165726    83.165726   \n",
       "36534                 0  38.843988 -122.759707    70.862404    70.362500   \n",
       "\n",
       "       Temp_pre_7  Wind_pre_30  Wind_pre_15  Wind_pre_7  Hum_pre_30  \\\n",
       "0       76.824675     4.341807     3.492857    3.262092   78.216590   \n",
       "1       32.618353     2.709764     2.881707    1.976471   70.840000   \n",
       "2       42.005750     3.364499     2.923830    2.695833   75.531629   \n",
       "3       64.656615     4.054982     3.398329    3.671282   44.778429   \n",
       "4       68.782609     1.331257     1.472949    1.424783   72.899478   \n",
       "...           ...          ...          ...         ...         ...   \n",
       "36530   39.987614     5.100510     5.694737    4.975000   62.971774   \n",
       "36531   65.620761     2.507911     2.553364    2.638542   51.010341   \n",
       "36532   66.054190     3.259176     2.705398    3.196648   65.671410   \n",
       "36533   82.700000     2.649395     2.649395    2.667722   43.755556   \n",
       "36534   71.533571     1.795485     1.628065    1.036905   50.521912   \n",
       "\n",
       "       Hum_pre_15  Hum_pre_7  Prec_pre_30  Prec_pre_15  Prec_pre_7  \\\n",
       "0       76.793750  76.381579          0.0          0.0         0.0   \n",
       "1       65.858911  55.505882         59.8          8.4         0.0   \n",
       "2       75.868613  76.812834        168.8         42.2        18.1   \n",
       "3       37.140811  35.353846         10.4          7.2         0.0   \n",
       "4       75.061381  77.924623         28.4         27.5         1.2   \n",
       "...           ...        ...          ...          ...         ...   \n",
       "36530   69.376658  68.118919         20.1         18.8         0.0   \n",
       "36531   50.264501  48.204861          4.6          0.0         0.0   \n",
       "36532   61.839572  54.625698         35.4          8.2         0.0   \n",
       "36533   43.755556  44.443975          0.0          0.0         0.0   \n",
       "36534   46.310627  37.178571          0.3          0.3         0.0   \n",
       "\n",
       "       remoteness  target  month  year   temp_avg  is_remote  did_rain  \\\n",
       "0        0.017923       0      2  2007  76.460297          0         0   \n",
       "1        0.184355       0     12  2006  40.944178          0         1   \n",
       "2        0.194544       0      2  2004  41.788067          0         1   \n",
       "3        0.487447       0      6  2005  64.048828          0         1   \n",
       "4        0.241894       0     11  2005  64.570703          0         1   \n",
       "...           ...     ...    ...   ...        ...        ...       ...   \n",
       "36530    0.365622       1      2  2015  38.698132          0         1   \n",
       "36531    0.199532       1      9  2015  66.690536          0         1   \n",
       "36532    0.331501       1     10  2015  65.318645          0         1   \n",
       "36533    0.097682       1      7  2015  83.010484          0         0   \n",
       "36534    0.167305       1      9  2015  70.919492          0         1   \n",
       "\n",
       "       Temp_pre_30_bin  Temp_pre_15_bin  Temp_pre_7_bin  discovery_month_Aug  \\\n",
       "0                    3                3               3                    0   \n",
       "1                    0                0               0                    0   \n",
       "2                    0                0               0                    0   \n",
       "3                    2                2               2                    0   \n",
       "4                    2                2               2                    0   \n",
       "...                ...              ...             ...                  ...   \n",
       "36530                0                0               0                    0   \n",
       "36531                2                2               2                    0   \n",
       "36532                2                2               2                    0   \n",
       "36533                3                3               3                    0   \n",
       "36534                2                2               2                    0   \n",
       "\n",
       "       discovery_month_Dec  discovery_month_Feb  discovery_month_Jan  \\\n",
       "0                        0                    1                    0   \n",
       "1                        1                    0                    0   \n",
       "2                        0                    1                    0   \n",
       "3                        0                    0                    0   \n",
       "4                        0                    0                    0   \n",
       "...                    ...                  ...                  ...   \n",
       "36530                    0                    1                    0   \n",
       "36531                    0                    0                    0   \n",
       "36532                    0                    0                    0   \n",
       "36533                    0                    0                    0   \n",
       "36534                    0                    0                    0   \n",
       "\n",
       "       discovery_month_Jul  discovery_month_Jun  discovery_month_Mar  \\\n",
       "0                        0                    0                    0   \n",
       "1                        0                    0                    0   \n",
       "2                        0                    0                    0   \n",
       "3                        0                    1                    0   \n",
       "4                        0                    0                    0   \n",
       "...                    ...                  ...                  ...   \n",
       "36530                    0                    0                    0   \n",
       "36531                    0                    0                    0   \n",
       "36532                    0                    0                    0   \n",
       "36533                    1                    0                    0   \n",
       "36534                    0                    0                    0   \n",
       "\n",
       "       discovery_month_May  discovery_month_Nov  discovery_month_Oct  \\\n",
       "0                        0                    0                    0   \n",
       "1                        0                    0                    0   \n",
       "2                        0                    0                    0   \n",
       "3                        0                    0                    0   \n",
       "4                        0                    1                    0   \n",
       "...                    ...                  ...                  ...   \n",
       "36530                    0                    0                    0   \n",
       "36531                    0                    0                    0   \n",
       "36532                    0                    0                    1   \n",
       "36533                    0                    0                    0   \n",
       "36534                    0                    0                    0   \n",
       "\n",
       "       discovery_month_Sep  state_AL  state_AR  state_AZ  state_CA  state_CO  \\\n",
       "0                        0         0         0         0         0         0   \n",
       "1                        0         0         0         0         0         0   \n",
       "2                        0         0         0         0         0         0   \n",
       "3                        0         0         0         0         0         0   \n",
       "4                        0         0         0         0         0         0   \n",
       "...                    ...       ...       ...       ...       ...       ...   \n",
       "36530                    0         0         0         0         0         0   \n",
       "36531                    1         0         0         0         0         1   \n",
       "36532                    0         0         0         0         0         0   \n",
       "36533                    0         0         0         0         1         0   \n",
       "36534                    1         0         0         0         1         0   \n",
       "\n",
       "       state_CT  state_DE  state_FL  state_GA  state_HI  state_IA  state_ID  \\\n",
       "0             0         0         0         0         0         0         0   \n",
       "1             0         0         0         0         0         0         0   \n",
       "2             0         0         0         0         0         0         0   \n",
       "3             0         0         0         0         0         0         0   \n",
       "4             0         0         0         0         0         0         0   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "36530         0         0         0         0         0         0         0   \n",
       "36531         0         0         0         0         0         0         0   \n",
       "36532         0         0         0         0         0         0         0   \n",
       "36533         0         0         0         0         0         0         0   \n",
       "36534         0         0         0         0         0         0         0   \n",
       "\n",
       "       state_IL  state_IN  state_KS  state_KY  state_LA  state_MA  state_MD  \\\n",
       "0             0         0         0         0         0         0         0   \n",
       "1             0         0         0         0         0         0         0   \n",
       "2             0         0         0         0         0         0         0   \n",
       "3             0         0         0         0         0         0         0   \n",
       "4             0         0         0         0         0         0         0   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "36530         0         0         1         0         0         0         0   \n",
       "36531         0         0         0         0         0         0         0   \n",
       "36532         0         0         1         0         0         0         0   \n",
       "36533         0         0         0         0         0         0         0   \n",
       "36534         0         0         0         0         0         0         0   \n",
       "\n",
       "       state_ME  state_MI  state_MN  state_MO  state_MS  state_MT  state_NC  \\\n",
       "0             0         0         0         0         0         0         0   \n",
       "1             0         0         0         0         0         0         0   \n",
       "2             0         0         0         0         1         0         0   \n",
       "3             0         0         0         0         0         0         0   \n",
       "4             0         0         0         0         0         0         0   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "36530         0         0         0         0         0         0         0   \n",
       "36531         0         0         0         0         0         0         0   \n",
       "36532         0         0         0         0         0         0         0   \n",
       "36533         0         0         0         0         0         0         0   \n",
       "36534         0         0         0         0         0         0         0   \n",
       "\n",
       "       state_ND  state_NE  state_NH  state_NJ  state_NM  state_NV  state_NY  \\\n",
       "0             0         0         0         0         0         0         0   \n",
       "1             0         0         0         0         0         0         0   \n",
       "2             0         0         0         0         0         0         0   \n",
       "3             0         0         0         0         0         1         0   \n",
       "4             0         0         0         0         0         0         0   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "36530         0         0         0         0         0         0         0   \n",
       "36531         0         0         0         0         0         0         0   \n",
       "36532         0         0         0         0         0         0         0   \n",
       "36533         0         0         0         0         0         0         0   \n",
       "36534         0         0         0         0         0         0         0   \n",
       "\n",
       "       state_OH  state_OK  state_OR  state_PA  state_PR  state_RI  state_SC  \\\n",
       "0             0         0         0         0         1         0         0   \n",
       "1             0         0         0         0         0         0         0   \n",
       "2             0         0         0         0         0         0         0   \n",
       "3             0         0         0         0         0         0         0   \n",
       "4             0         0         0         0         0         0         0   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "36530         0         0         0         0         0         0         0   \n",
       "36531         0         0         0         0         0         0         0   \n",
       "36532         0         0         0         0         0         0         0   \n",
       "36533         0         0         0         0         0         0         0   \n",
       "36534         0         0         0         0         0         0         0   \n",
       "\n",
       "       state_SD  state_TN  state_TX  state_UT  state_VA  state_VT  state_WA  \\\n",
       "0             0         0         0         0         0         0         0   \n",
       "1             0         1         0         0         0         0         0   \n",
       "2             0         0         0         0         0         0         0   \n",
       "3             0         0         0         0         0         0         0   \n",
       "4             0         0         1         0         0         0         0   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "36530         0         0         0         0         0         0         0   \n",
       "36531         0         0         0         0         0         0         0   \n",
       "36532         0         0         0         0         0         0         0   \n",
       "36533         0         0         0         0         0         0         0   \n",
       "36534         0         0         0         0         0         0         0   \n",
       "\n",
       "       state_WI  state_WV  state_WY  Vegetation_4  Vegetation_9  \\\n",
       "0             0         0         0             0             0   \n",
       "1             0         0         0             0             0   \n",
       "2             0         0         0             0             0   \n",
       "3             0         0         0             0             0   \n",
       "4             0         0         0             0             0   \n",
       "...         ...       ...       ...           ...           ...   \n",
       "36530         0         0         0             0             0   \n",
       "36531         0         0         0             0             0   \n",
       "36532         0         0         0             0             0   \n",
       "36533         0         0         0             0             0   \n",
       "36534         0         0         0             0             0   \n",
       "\n",
       "       Vegetation_12  Vegetation_14  Vegetation_15  Vegetation_16  \\\n",
       "0                  1              0              0              0   \n",
       "1                  0              0              1              0   \n",
       "2                  0              0              0              1   \n",
       "3                  0              0              0              0   \n",
       "4                  1              0              0              0   \n",
       "...              ...            ...            ...            ...   \n",
       "36530              0              0              0              0   \n",
       "36531              0              1              0              0   \n",
       "36532              0              0              0              0   \n",
       "36533              0              0              0              0   \n",
       "36534              0              0              0              0   \n",
       "\n",
       "       longitude_bin  west_coast  very_windy_30  very_windy_15  very_windy_7  \\\n",
       "0                  3           0              1              1             1   \n",
       "1                  2           0              0              0             0   \n",
       "2                  2           0              0              0             0   \n",
       "3                  0           1              1              1             1   \n",
       "4                  1           0              0              0             0   \n",
       "...              ...         ...            ...            ...           ...   \n",
       "36530              1           0              1              1             1   \n",
       "36531              1           1              0              0             0   \n",
       "36532              1           0              0              0             0   \n",
       "36533              0           1              0              0             0   \n",
       "36534              0           1              0              0             0   \n",
       "\n",
       "       low_humid_30  low_humid_15  low_humid_7  \n",
       "0                 0             0            0  \n",
       "1                 0             0            0  \n",
       "2                 0             0            0  \n",
       "3                 1             1            1  \n",
       "4                 0             0            0  \n",
       "...             ...           ...          ...  \n",
       "36530             0             0            0  \n",
       "36531             0             0            1  \n",
       "36532             0             0            0  \n",
       "36533             1             1            1  \n",
       "36534             0             1            1  \n",
       "\n",
       "[36535 rows x 100 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Feature data frame and Target data frame\n",
    "X = df.drop(columns='target',axis=1)\n",
    "y = df['target']\n",
    "\n",
    "# Creating Train Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "\n",
    "# Scaling is Needed for Knn\n",
    "scaler = StandardScaler()  \n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)  \n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All 3 of the below models use basic parameters to give baseline information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LogRegTest(input_x,input_y):\n",
    "    lr = LogisticRegression(random_state=1,C=1e9)\n",
    "    lr.fit(input_x,input_y)\n",
    "    pred_train = lr.predict(input_x)\n",
    "    score = f1_score(input_y,pred_train,zero_division=1)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KnnTest(input_x,input_y):\n",
    "    knn = KNeighborsClassifier(n_neighbors=5,algorithm='auto',weights='uniform')\n",
    "    knn.fit(input_x,input_y)\n",
    "    pred_train = knn.predict(input_x)\n",
    "    score = f1_score(input_y,pred_train,zero_division=1)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DTreeTest(input_x,input_y):\n",
    "    tree = DecisionTreeClassifier(max_depth=12, min_samples_split=17,criterion='gini',min_samples_leaf=4)\n",
    "    tree.fit(input_x,input_y)\n",
    "    pred_train = tree.predict(input_x)\n",
    "    score = f1_score(input_y,pred_train,zero_division=1)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def three_class_test(X_train,y_train):\n",
    "    print('LogReg F1: ', LogRegTest(X_train,y_train))\n",
    "    print('Knn F1: ', KnnTest(X_train,y_train))\n",
    "    print('Dtree F1: ', DTreeTest(X_train,y_train))\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline with Test Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  0.6869526495472763\n",
      "Test:  0.6924137931034484\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "lr = LogisticRegression(random_state=2)\n",
    "\n",
    "lr.fit(X_train,y_train)\n",
    "\n",
    "pred_train = lr.predict(X_train)\n",
    "\n",
    "pred_test = lr.predict(X_test)\n",
    "\n",
    "score_train = f1_score(y_train,pred_train)\n",
    "score_test = f1_score(y_test,pred_test)\n",
    "\n",
    "print('Train: ',score_train)\n",
    "print('Test: ',score_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  0.6869526495472763\n",
      "Test:  0.6924137931034484\n"
     ]
    }
   ],
   "source": [
    "# KNN\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "y_pred_train = knn.predict(X_train)\n",
    "\n",
    "y_pred_test = knn.predict(X_test)\n",
    "\n",
    "score_train = f1_score(y_train,pred_train)\n",
    "score_test = f1_score(y_test,pred_test)\n",
    "\n",
    "print('Train: ',score_train)\n",
    "print('Test: ',score_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  1.0\n",
      "Test:  0.7305644302449416\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree\n",
    "tree = DecisionTreeClassifier()\n",
    "\n",
    "tree = tree.fit(X_train,y_train)\n",
    "\n",
    "pred_train = tree.predict(X_train)\n",
    "\n",
    "pred_test = tree.predict(X_test)\n",
    "\n",
    "score_train = f1_score(y_train,pred_train)\n",
    "score_test = f1_score(y_test,pred_test)\n",
    "\n",
    "print('Train: ',score_train)\n",
    "print('Test: ',score_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quite good results but as you can see there is a lot of over fitting with the decision tree. In order to improve results feature selection will be performed to identify the most important features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state = 99, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter Method Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import chi2, f_classif, mutual_info_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# instantiating a feature selector object\n",
    "feature_selector = SelectKBest(mutual_info_classif,15)\n",
    "\n",
    "# fitting to our data\n",
    "feature_selector.fit(X_train,y_train)\n",
    "\n",
    "# features that we keep\n",
    "selected_filter = X_train.columns[feature_selector.get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogReg F1:  0.39080459770114945\n",
      "Knn F1:  0.6587261785356069\n",
      "Dtree F1:  0.8358473824312334\n"
     ]
    }
   ],
   "source": [
    "three_class_test(X_train[selected_filter],y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recursive Feature Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Using Logistic Regression as the estimation of 'goodness'\n",
    "estimator = LogisticRegression()\n",
    "# creating a selector object\n",
    "feature_selector = RFECV(estimator=estimator, step=1, cv=5,n_jobs=-1,min_features_to_select=8)\n",
    "# fitting to our data\n",
    "feature_selector.fit(X_train, y_train)\n",
    "# Extracting most important features\n",
    "selected_wrapper = X_train.columns[feature_selector.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogReg F1:  0.671244635193133\n",
      "Knn F1:  0.7944142746314973\n",
      "Dtree F1:  0.7839169218479564\n"
     ]
    }
   ],
   "source": [
    "three_class_test(X_train[selected_wrapper],y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test Split Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns='target',axis=1)\n",
    "y = df['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state = 99, test_size=0.2)\n",
    "\n",
    "X_train = X_train[selected_filter]\n",
    "X_test = X_test[selected_filter]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class Imbalance Handling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upsampling using reampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# isolating training data\n",
    "training = pd.concat([X_train,y_train],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting by target value\n",
    "large = training[training.target == 1]\n",
    "small = training[training.target == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "large count: 4512\n",
      "small count: 24716\n"
     ]
    }
   ],
   "source": [
    "print('large count: '+ str(len(large)))\n",
    "print('small count: '+ str(len(small)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of upsampled large:  24716\n"
     ]
    }
   ],
   "source": [
    "# upsampling with replacement to match majority class size\n",
    "large_upsampled = resample(large,\n",
    "                        replace=True,\n",
    "                        n_samples=len(small),\n",
    "                        random_state=99)\n",
    "print('Size of upsampled large: ',len(large_upsampled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combining back together\n",
    "upsampled = pd.concat([small,large_upsampled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating training data\n",
    "X_train_upsample = upsampled.drop(columns='target')\n",
    "y_train_upsample = upsampled.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Over-sampling SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating synthetic rows using SMOTE\n",
    "sm = SMOTE(random_state=99)\n",
    "X_train_smote, y_train_smote = sm.fit_sample(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normal Downsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_downsampled = resample(small,\n",
    "                            replace = False,\n",
    "                            n_samples=len(small),\n",
    "                            random_state=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "downsampled = pd.concat([small_downsampled,large])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_downsample = downsampled.drop(columns='target')\n",
    "y_train_downsample = downsampled.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tomek Links DownSampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from imblearn.under_sampling import TomekLinks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled dataset shape Counter({0: 23729, 1: 4512})\n"
     ]
    }
   ],
   "source": [
    "tl = TomekLinks()\n",
    "X_res, y_res = tl.fit_resample(X_train, y_train)\n",
    "print('Resampled dataset shape %s' % Counter(y_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove Tomek links\n",
    "tl = TomekLinks()\n",
    "X_train_tomek, y_train_tomek = tl.fit_sample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Smote and Upsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogReg F1:  0.7723562415183002\n",
      "Knn F1:  0.9261159956228067\n",
      "Dtree F1:  0.9200600835408136\n"
     ]
    }
   ],
   "source": [
    "# Upsampling\n",
    "three_class_test(X_train_upsample[selected_filter],y_train_upsample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogReg F1:  0.7689551266389771\n",
      "Knn F1:  0.9237136675759571\n",
      "Dtree F1:  0.9126258977519017\n"
     ]
    }
   ],
   "source": [
    "# SMOTE\n",
    "three_class_test(X_train_smote[selected_filter],y_train_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogReg F1:  0.3956689868522815\n",
      "Knn F1:  0.6587261785356069\n",
      "Dtree F1:  0.8351983723296033\n"
     ]
    }
   ],
   "source": [
    "# Normal Downsampling\n",
    "three_class_test(X_train_downsample[selected_filter],y_train_downsample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogReg F1:  0.5290004113533525\n",
      "Knn F1:  0.7002724795640327\n",
      "Dtree F1:  0.8400500625782228\n"
     ]
    }
   ],
   "source": [
    "# Tomek Links downsampling\n",
    "three_class_test(X_train_tomek[selected_filter],y_train_tomek)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this we can see that upsamping and smote are the best method for dealing with class imbalance. Smote will be used from now on as we want a very interpretable model so we care more about logistic regression and decision tree scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Feature Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Train Test split using selected balancing and features\n",
    "X_train_selected = X_train_smote\n",
    "y_train_selected = y_train_smote\n",
    "\n",
    "X_test_selected = X_test[selected_filter]\n",
    "y_test_selected = y_test\n",
    "\n",
    "# Scaling is Needed for Knn\n",
    "scaler = StandardScaler()  \n",
    "scaler.fit(X_train_selected)\n",
    "\n",
    "X_train_selected_scaled = scaler.transform(X_train_selected)  \n",
    "X_test_selected_scaled = scaler.transform(X_test_selected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  0.767960194946879\n",
      "Test:  0.516246583662314\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "lr = LogisticRegression()\n",
    "\n",
    "lr.fit(X_train_selected,y_train_selected)\n",
    "\n",
    "pred_train = lr.predict(X_train_selected)\n",
    "\n",
    "pred_test = lr.predict(X_test_selected)\n",
    "\n",
    "score_train = f1_score(y_train_selected,pred_train)\n",
    "score_test = f1_score(y_test_selected,pred_test)\n",
    "\n",
    "print('Train: ',score_train)\n",
    "print('Test: ',score_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  0.951154052603328\n",
      "Test:  0.6697424067666282\n"
     ]
    }
   ],
   "source": [
    "# KNN\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "knn.fit(X_train_selected_scaled, y_train_selected)\n",
    "\n",
    "y_pred_train = knn.predict(X_train_selected_scaled)\n",
    "\n",
    "y_pred_test = knn.predict(X_test_selected_scaled)\n",
    "\n",
    "score_train = f1_score(y_train_selected,y_pred_train)\n",
    "score_test = f1_score(y_test_selected,y_pred_test)\n",
    "\n",
    "print('Train: ',score_train)\n",
    "print('Test: ',score_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  1.0\n",
      "Test:  0.6882655077044646\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree\n",
    "tree = DecisionTreeClassifier()\n",
    "\n",
    "tree = tree.fit(X_train_selected,y_train_selected)\n",
    "\n",
    "pred_train = tree.predict(X_train_selected)\n",
    "\n",
    "pred_test = tree.predict(X_test_selected)\n",
    "\n",
    "score_train = f1_score(y_train_selected,pred_train)\n",
    "score_test = f1_score(y_test,pred_test)\n",
    "\n",
    "print('Train: ',score_train)\n",
    "print('Test: ',score_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The train set results are better but there seems to be overfitting. Grid Searching should fine the optimal hyper parameters for these models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = { \n",
    "    'penalty': ['l2'],\n",
    "    'C': [1e9,100,1,0.1,0.05,],\n",
    "    'max_iter':[1000]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 5 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:   31.8s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   46.7s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=LogisticRegression(), n_jobs=-1,\n",
       "             param_grid={'C': [1000000000.0, 100, 1, 0.1, 0.05],\n",
       "                         'max_iter': [1000], 'penalty': ['l2']},\n",
       "             scoring='f1', verbose=1)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_log=GridSearchCV(LogisticRegression(),\n",
    "                         param_grid, \n",
    "                         cv=10, \n",
    "                         scoring='f1', \n",
    "                         verbose=1, \n",
    "                         n_jobs=-1)\n",
    "\n",
    "grid_log.fit(X_train_selected,y_train_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7687995682591955\n",
      "{'C': 0.05, 'max_iter': 1000, 'penalty': 'l2'}\n",
      "LogisticRegression(C=0.05, max_iter=1000)\n"
     ]
    }
   ],
   "source": [
    "# Single best score achieved across all params (min_samples_split)\n",
    "print(grid_log.best_score_)\n",
    "\n",
    "# Dictionary containing the parameters (min_samples_split) used to generate that score\n",
    "print(grid_log.best_params_)\n",
    "\n",
    "# Actual model object fit with those best parameters\n",
    "# Shows default parameters that we did not specify\n",
    "print(grid_log.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.892021\n",
      "F1: 0.688266\n",
      "Recall: 0.781867\n",
      "Precision: 0.614679\n"
     ]
    }
   ],
   "source": [
    "#Predict the response for test dataset\n",
    "y_pred_test = grid_log.best_estimator_.predict(X_test_selected)\n",
    "\n",
    "y_pred_train = grid_log.best_estimator_.predict(X_train_selected)\n",
    "\n",
    "\n",
    "test_f1 = f1_score(y_test_selected, pred_test)\n",
    "test_acc = accuracy_score(y_test_selected, pred_test)\n",
    "test_recall = recall_score(y_test_selected, pred_test)\n",
    "test_precision = precision_score(y_test_selected,pred_test)\n",
    "\n",
    "print(\"Accuracy: %f\" % (test_acc))\n",
    "print(\"F1: %f\" % (test_f1))\n",
    "print(\"Recall: %f\" % (test_recall))\n",
    "print('Precision: %f' % (test_precision))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state = 99, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid={\n",
    "    'criterion': ['gini'],\n",
    "    'max_depth': range(10,15,1),\n",
    "    'min_samples_split': range(1,5,1),\n",
    "    'min_samples_leaf': range(1,5,1)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 80 candidates, totalling 800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done 212 tasks      | elapsed:   11.7s\n",
      "[Parallel(n_jobs=-1)]: Done 462 tasks      | elapsed:   25.7s\n",
      "[Parallel(n_jobs=-1)]: Done 800 out of 800 | elapsed:   47.6s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=DecisionTreeClassifier(), n_jobs=-1,\n",
       "             param_grid={'criterion': ['gini'], 'max_depth': range(10, 15),\n",
       "                         'min_samples_leaf': range(1, 5),\n",
       "                         'min_samples_split': range(1, 5)},\n",
       "             scoring='f1', verbose=1)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_tree=GridSearchCV(DecisionTreeClassifier(),\n",
    "                         param_grid, \n",
    "                         cv=10, \n",
    "                         scoring='f1', \n",
    "                         verbose=1, \n",
    "                         n_jobs=-1)\n",
    "\n",
    "grid_tree.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8049544905593612\n",
      "{'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 2}\n",
      "DecisionTreeClassifier(max_depth=10, min_samples_leaf=2)\n"
     ]
    }
   ],
   "source": [
    "# Single best score achieved across all params (min_samples_split)\n",
    "print(grid_tree.best_score_)\n",
    "\n",
    "# Dictionary containing the parameters (min_samples_split) used to generate that score\n",
    "print(grid_tree.best_params_)\n",
    "\n",
    "# Actual model object fit with those best parameters\n",
    "# Shows default parameters that we did not specify\n",
    "print(grid_tree.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTreeClassifier(max_depth=10, max_leaf_nodes=40,min_samples_leaf=2,min_samples_split=3,random_state=80)\n",
    "\n",
    "tree = tree.fit(X_train,y_train)\n",
    "\n",
    "pred_train = tree.predict(X_train)\n",
    "\n",
    "pred_test = tree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.953196\n",
      "F1: 0.823347\n",
      "Recall: 0.715440\n",
      "Precision: 0.969586\n"
     ]
    }
   ],
   "source": [
    "test_f1 = f1_score(y_test,pred_test)\n",
    "test_acc = accuracy_score(y_test, pred_test)\n",
    "test_recall = recall_score(y_test, pred_test)\n",
    "test_precision = precision_score(y_test,pred_test)\n",
    "\n",
    "print(\"Accuracy: %f\" % (test_acc))\n",
    "print(\"F1: %f\" % (test_f1))\n",
    "print(\"Recall: %f\" % (test_recall))\n",
    "print('Precision: %f' % (test_precision))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XG BOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error,accuracy_score, f1_score, roc_auc_score, recall_score, precision_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This includes max_depth, min_child_weight and gamma.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_clf = xgb.XGBClassifier(objective ='binary:logistic', \n",
    "                           colsample_bytree = 0.5, \n",
    "                           min_child_weight = 5,\n",
    "                           learning_rate = 0.1,\n",
    "                           max_depth = 5, \n",
    "                           n_estimators = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(colsample_bytree=0.5, max_depth=5, min_child_weight=5,\n",
       "              n_estimators=500)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg_clf.fit(X_train_selected,y_train_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.939647\n",
      "F1: 0.792666\n",
      "Recall: 0.756732\n",
      "Precision: 0.832182\n"
     ]
    }
   ],
   "source": [
    "preds = xg_clf.predict(X_test_selected)\n",
    "\n",
    "test_f1 = f1_score(y_test_selected, preds)\n",
    "test_acc = accuracy_score(y_test_selected, preds)\n",
    "test_recall = recall_score(y_test_selected, preds)\n",
    "test_precision = precision_score(y_test_selected,preds)\n",
    "\n",
    "print(\"Accuracy: %f\" % (test_acc))\n",
    "print(\"F1: %f\" % (test_f1))\n",
    "print(\"Recall: %f\" % (test_recall))\n",
    "print('Precision: %f' % (test_precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "xgb.plot_importance(xg_clf,max_num_features = 15)\n",
    "plt.rcParams['figure.figsize'] = [5, 5]\n",
    "plt.tick_params(labelsize='large')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Searched XG Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV, KFold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_xgb = xgb.XGBClassifier(objective = 'binary:logistic')\n",
    "param_dist = {'n_estimators': [100,300,500],\n",
    "              'learning_rate': [0.1,0.07,0.05,0.03,0.01],\n",
    "              'max_depth': [3, 4, 5, 6, 7],\n",
    "              'colsample_bytree': [0.5,0.45,0.4],\n",
    "              'min_child_weight': [1, 2, 3]\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate the Gridsearch model\n",
    "gsearch1 = GridSearchCV(\n",
    "    estimator = clf_xgb,\n",
    "    param_grid = param_dist, \n",
    "    scoring='f1',\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    iid=False, \n",
    "    cv=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsearch1.fit(X_train_smote[selected_wrapper],y_train_smote)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsearch1.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These hyperparameters will be used in the XGBoost above the grid search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some info about xgboost:\n",
    "* Generally, importance provides a score that indicates how useful or valuable each feature was in the construction of the boosted decision trees within the model. The more an attribute is used to make key decisions with decision trees, the higher its relative importance.\n",
    "* Importance is calculated for a single decision tree by the amount that each attribute split point improves the performance measure, weighted by the number of observations the node is responsible for. The performance measure may be the purity (Gini index) used to select the split points or another more specific error function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
